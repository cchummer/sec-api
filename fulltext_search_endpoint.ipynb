{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMhKqVj8PLu1MhnrYu5Gaso"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# HTTP lib\n",
        "import requests\n",
        "\n",
        "# Date objects\n",
        "from datetime import date\n",
        "\n",
        "# JSON\n",
        "import json"
      ],
      "metadata": {
        "id": "uGQ6vEM-bG2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# \"EDGAR Full Text Search\"\n",
        "\"New versatile tool lets you search for keywords and phrases in over 20 years of EDGAR filings, and filter by date, company, person, filing category or location.\" (https://www.sec.gov/edgar/searchedgar/companysearch -> https://www.sec.gov/edgar/search/). FAQ [here](https://www.sec.gov/edgar/search/efts-faq.html).\n",
        "\n",
        "You can query for text/strings in forms filtered by form type, date range, location of principal office of the filing entity and name/CIK (both use the same parameter) of the filing entity/person. \n",
        "\n",
        "**Note:** The two useful search parameters which are not offered by [edgar/search/](https://) are search by file number and SIC number. Both are displayed in the table of results of a given query, but in order to search via file number, it is required to use the \"company search\" endpoint https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&filenum=XXX-XXXX. **See the corresponding notebook company_search_endpoint**. (It is actually possible to search by file number via the company database search endpoint as well)"
      ],
      "metadata": {
        "id": "ahMdL72HL_YG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parameters of the Query\n",
        "The base url of the endpoint is https://efts.sec.gov/LATEST/search-index.\n",
        "We send a POST request with the following parameters sent as a JSON string, see https://linuxpip.org/post-python-requests/ section \"Send POST request with JSON data as string\" for example. \n",
        "\n",
        "A list of parameters available (as discovered so far):\n",
        "```\n",
        "- q=TARGET_WORDS : list of words, separated by spaces, to search for in filing documents. Use quotes to match an exact multi-word string. See https://www.sec.gov/edgar/searchedgar/search_help.htm \n",
        "- entityName=NAME_OR_CIK_OF_FILING_ENTITY : can either be the CIK of the filing entity, or the beginning (or full) name of the filing entity. \n",
        "- forms=LIST_OF_TARGET_FORM_TYPES : list of form types to query for. See fulltext_forms_list.txt for full list (via 9/14/22).\n",
        "- dateRange=SIMPLE_FORMAT_DATE_RANGE : Note: If not set, default is 5 years. There are a few possible values here:\n",
        "  1. all : query filings from as far back as possible (site states since 2001)\n",
        "  2. 10y,5y,1y,30d : pretty self explanatory. Strange that you cannot enter custom versions of these such as 2y etc but oh well\n",
        "  3. custom : custom time-frame. The endpoint will expect the following 2 parameters in this case:\n",
        "    - startdt=YYYY-MM-DD\n",
        "    - enddt=YYYY-MM-DD\n",
        "- locationCode=STATE_OR_COUNTRY_CODE : Seems overruled by locationCodes. Makes no difference when including in manual query\n",
        "- locationCodes=LIST_OF_STATE_OR_COUNTRY_CODES : List of either 2 letter state abbreviation or country code, see edgar_state_codes.txt\n",
        "- from=RESULT_INDEX : return the next 100 results starting from RESULT_INDEX\n",
        "- page=PAGE_NUM doesn't not seem to matter since we are not viewing in a browser, \"from\" seems to be the parameter controlling the results returned\n",
        "- category=custom : not sure what it does, page seems to function the same without including it\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "D0JTtQFYRspq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Response\n",
        "If the query is successful, the server sends back a JSON structure of results in the following format:\n",
        "\n",
        "\n",
        "```\n",
        "{\n",
        "   \"took\":422,\n",
        "   \"timed_out\":false,\n",
        "   \"_shards\":{\n",
        "      \"total\":50,\n",
        "      \"successful\":50,\n",
        "      \"skipped\":0,\n",
        "      \"failed\":0\n",
        "   },\n",
        "   \"hits\":{\n",
        "      \"total\":{\n",
        "         \"value\":6308,\n",
        "         \"relation\":\"eq\"\n",
        "      },\n",
        "      \"max_score\":18.2674,\n",
        "      \"hits\":[\n",
        "         {\n",
        "            \"_index\":\"edgar_file\",\n",
        "            \"_type\":\"_doc\",\n",
        "            \"_id\":\"0001193125-16-760799:d275549dex1012.htm\",\n",
        "            \"_score\":18.2674,\n",
        "            \"_source\":{\n",
        "               \"ciks\":[\n",
        "                  \"0001603978\"\n",
        "               ],\n",
        "               \"period_ending\":null,\n",
        "               \"root_form\":\"10-12B\",\n",
        "               \"file_num\":[\n",
        "                  \"001-36426\"\n",
        "               ],\n",
        "               \"display_names\":[\n",
        "                  \"AquaBounty Technologies, Inc.  (AQB)  (CIK 0001603978)\"\n",
        "               ],\n",
        "               \"xsl\":null,\n",
        "               \"sequence\":\"16\",\n",
        "               \"file_date\":\"2016-11-07\",\n",
        "               \"biz_states\":[\n",
        "                  \"MA\"\n",
        "               ],\n",
        "               \"sics\":[\n",
        "                  \"0900\"\n",
        "               ],\n",
        "               \"form\":\"10-12B\",\n",
        "               \"adsh\":\"0001193125-16-760799\",\n",
        "               \"film_num\":[\n",
        "                  \"161976497\"\n",
        "               ],\n",
        "               \"biz_locations\":[\n",
        "                  \"Maynard, MA\"\n",
        "               ],\n",
        "               \"file_type\":\"EX-10.12\",\n",
        "               \"file_description\":\"EX-10.12\",\n",
        "               \"inc_states\":[\n",
        "                  \"DE\"\n",
        "               ],\n",
        "               \"items\":[\n",
        "                  \n",
        "               ]\n",
        "            }\n",
        "         },\n",
        "         {\n",
        "           ... one per hit...\n",
        "         },\n",
        "         ...\n",
        "   },\n",
        "   \"aggregations\":{\n",
        "     ...\n",
        "   },\n",
        "   \"query\":{\n",
        "     ...\n",
        "   }\n",
        "}\n",
        "```\n",
        "\n",
        "The hits dictionary contains a couple of important pieces of information. Within the \"total\" dictionary, the number of total results is given. In the \"hits\" sublist, a dictionary object exists for up to the first 100 results. We use these two facts to loop through in the case that there is > 100 results. This result dictionary contains the specific document filename \"_id\", along with another dictionary \"_source\". The \"_source\" dictionary contains the accession number and filing CIKs (may be multiple, in the case of a form 4 for example). The filing should be accessible via either CIK under the same accession number.\n",
        "\n",
        "The aggregations dictionary may also be of interest, as it contains statistics about the different entities, form types, etc present in the list of results. \n",
        "\n",
        "\"query\" contains information about the query that was made."
      ],
      "metadata": {
        "id": "6Fv1nKvnGolJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iig9XTaMLD7D"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Method which returns a list of result_dictionary structures as declared below follow for each result.\n",
        "# Either a query string, entity name / CIK, or form type(s) must be entered for successful query. Default to \"all\" date range (left blank would default to 5yr)\n",
        "# Note that forms are expected in proper list format\n",
        "\n",
        "Format of result_dict: {\n",
        "  \"filename\" : DOCUMENT_FILENAME, # Not full path!\n",
        "  \"cik\" : [] LIST_OF_CIK_NUM(S),\n",
        "  \"accession\" : ACCESSION_NUM,\n",
        "  \"file_num\" : [] LIST_OF_FILING_NUMBER(S),\n",
        "  \"film_num\" : [] LIST_OF_FILM_NUMBER(S),\n",
        "  \"display_name\" : [] LIST_OF_ENTITY_NAME(S),\n",
        "  \"sic\" : [] LIST_OF_SICS_OF_FILER(S),\n",
        "  \"form\" : ROOT_FORM_TYPE,\n",
        "  \"period_ending\" : PERIOD_ENDED, # Period and file date are both given in the same YYYY-MM-DD format\n",
        "  \"file_date\" : FILING_DATE,\n",
        "  \"file_desc\" : FILE_DESCRIPTION,\n",
        "  \"biz_city\" : [] LIST_OF_CITY/CITIES_OF_FILER(S),\n",
        "  \"biz_state\" : [] LIST_OF_STATE(S)_OR_COUNTRY_CODE(S)_OF_FILERS, # See edgar_state_codes.txt\n",
        "  \"inc_in\" : [] LIST_OF_STATE(S)_OR_COUNTRY(S)_OF_INCORP # See edgar_state_codes.txt\n",
        "}\n",
        "\n",
        "Note: cik, display_name, biz_city, and inc_in lists seem to be returned in sync/order and if a value is missing for one entry, an empty list entry is present.\n",
        " The other elements will not create empty entries if there is no value for a filer, so don't rely on them being the sane \"depth\" as the lists just mentioned. \n",
        "\"\"\"\n",
        "\n",
        "def list_results_full_text_query(query_string = \"\", entity_name = \"\", target_forms_list = (), date_range = \"all\", location_code = \"\", target_category = \"\", start_dt = \"\", end_dt = \"\"):\n",
        "\n",
        "  # List we will return\n",
        "  results_list = []\n",
        "\n",
        "  # Headers\n",
        "  request_headers = { \n",
        "      \"host\" : \"efts.sec.gov\",\n",
        "      \"accept-language\" : \"en-US,en;q=0.9\",\n",
        "      \"User-Agent\" : \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\",\n",
        "      \"origin\" : \"https://www.sec.gov\", # Not sure how necessary these are, kept just to be safe\n",
        "      \"referer\" : \"https://www.sec.gov/\",\n",
        "      \"sec-fetch-dest\" : \"empty\",\n",
        "      \"sec-fetch-mode\" : \"cors\",\n",
        "      \"sec-fetch-site\" : \"same-site\"\n",
        "      }\n",
        "\n",
        "  # Copy parameters into dictionary\n",
        "  query_data = { \n",
        "      \"q\" : query_string,\n",
        "      \"entityName\" : entity_name,\n",
        "      \"forms\" : target_forms_list,\n",
        "      \"dateRange\" : date_range,\n",
        "      \"startdt\" : \"\",\n",
        "      \"enddt\" : \"\",\n",
        "      \"locationCode\" : location_code,\n",
        "      \"from\" : 0,\n",
        "      \"category\" : target_category\n",
        "  }\n",
        "  # Copy start and end date if applicable\n",
        "  if date_range == \"custom\":\n",
        "    if (type(start_dt) != date or type(end_dt) != date):\n",
        "      print(\"Invalid start/end date structure entered. Must be a date object\")\n",
        "      return results_list\n",
        "\n",
        "    query_data[\"startdt\"] = \"{}-{}-{}\".format(start_dt.year, str(start_dt.month).zfill(2), str(start_dt.day).zfill(2))\n",
        "    query_data[\"enddt\"] = \"{}-{}-{}\".format(end_dt.year, str(end_dt.month).zfill(2), str(end_dt.day).zfill(2))\n",
        "\n",
        "  # Send request \n",
        "  response = requests.post(url = \"https://efts.sec.gov/LATEST/search-index/\", headers = request_headers, json = query_data) # Notice difference when sending JSON string instead of data\n",
        "  response.raise_for_status()\n",
        "\n",
        "  # Server also responds with JSON as a string, read it into dictionary\n",
        "  response_dict = json.loads(response.content)\n",
        "\n",
        "  # Only 100 results are given back at a time. There is a count of total results in hits->total->value. Record it so we can send multiple requests if needed\n",
        "  hits_total = 0\n",
        "  hits_parsed = 0 \n",
        "  if \"value\" in response_dict[\"hits\"][\"total\"]:\n",
        "    hits_total = response_dict[\"hits\"][\"total\"][\"value\"]\n",
        "  else:\n",
        "    print(\"Failed to read number of hits. Results returned may be limited\")\n",
        "\n",
        "  # Loop will break when we have read all results\n",
        "  while True:\n",
        "\n",
        "    # Loop through hits->hits list\n",
        "    try:\n",
        "      for hit_index, current_hit in enumerate(response_dict[\"hits\"][\"hits\"]):\n",
        "\n",
        "        # Create dictionary for the result\n",
        "        result_dict = {\n",
        "            \"filename\" : \"\",\n",
        "            \"cik\" : [],\n",
        "            \"accession\" : \"\",\n",
        "            \"file_num\" : [],\n",
        "            \"film_num\" : [],\n",
        "            \"display_name\" : [],\n",
        "            \"sic\" : [],\n",
        "            \"form\" : \"\",\n",
        "            \"period_ending\" : \"\",\n",
        "            \"file_date\" : \"\",\n",
        "            \"file_desc\" : \"\",\n",
        "            \"biz_city\" : [],\n",
        "            \"biz_state\" : [], \n",
        "            \"inc_in\" : []\n",
        "        }\n",
        "        \n",
        "        # Grab the one thing outside the _source dictionary, the filename. Accession number is prepended, i.e.: \"0001127602-12-017271:scheduleto-goldreserveinc711.htm\". Split by colon and disregard first word\n",
        "        id_entry_split = current_hit[\"_id\"].split(\":\")\n",
        "        if len(id_entry_split) != 2: \n",
        "          print(\"Result filename is in unexpected format (inspect endpoint for any changes), skipping.\")\n",
        "          continue\n",
        "        \n",
        "        result_dict[\"filename\"] = id_entry_split[1]\n",
        "\n",
        "        # Now grab info from _source dictionary\n",
        "        source_dict = current_hit[\"_source\"]\n",
        "\n",
        "        # Check the critical keys exist in order for us to at least build a link\n",
        "        if (len(source_dict) and \"ciks\" in source_dict and \"adsh\" in source_dict):\n",
        "          \n",
        "          # In case we attempt to access a missing key\n",
        "          try:\n",
        "\n",
        "            # Go through result_dict in the order we declared it\n",
        "\n",
        "            # cik\n",
        "            for current_cik in source_dict[\"ciks\"]:\n",
        "              result_dict[\"cik\"].append(current_cik.zfill(10))\n",
        "            \n",
        "            # accession\n",
        "            result_dict[\"accession\"] = source_dict[\"adsh\"]\n",
        "\n",
        "            # file_num\n",
        "            for current_filenum in source_dict[\"file_num\"]:\n",
        "              result_dict[\"file_num\"].append(current_filenum)\n",
        "            \n",
        "            # film_num\n",
        "            for current_filmnum in source_dict[\"film_num\"]:\n",
        "              result_dict[\"film_num\"].append(current_filmnum)\n",
        "\n",
        "            # display_name. Comes in this format: \"AbCellera Biologics Inc.  (ABCL)  (CIK 0001703057)\". Split it by double spaces (\"  \") and disregard the [1] and [2] elements. \n",
        "            # Can always change if we decide we want to scrape tickers from here\n",
        "            for current_dn in source_dict[\"display_names\"]:\n",
        "              result_dict[\"display_name\"].append(current_dn.split(\"  \")[0])\n",
        "            \n",
        "            # sic\n",
        "            for current_sic in source_dict[\"sics\"]:\n",
        "              result_dict[\"sic\"].append(current_sic)\n",
        "\n",
        "            # form\n",
        "            result_dict[\"form\"] = source_dict[\"root_form\"]\n",
        "            if len(result_dict[\"form\"]) == 0:\n",
        "              result_dict[\"form\"] = source_dict[\"form\"] # Might as well try the other option as backup. Haven't come across either not being set in a result, but hey.\n",
        "\n",
        "            # period_ending\n",
        "            result_dict[\"period_ending\"] = source_dict[\"period_ending\"]\n",
        "\n",
        "            # file_date\n",
        "            result_dict[\"file_date\"] = source_dict[\"file_date\"]\n",
        "\n",
        "            # file_desc\n",
        "            result_dict[\"file_desc\"] = source_dict[\"file_description\"]\n",
        "            \n",
        "            # biz_city\n",
        "            for current_city in source_dict[\"biz_locations\"]:\n",
        "              result_dict[\"biz_city\"].append(current_city)\n",
        "            \n",
        "            # biz_state\n",
        "            for current_state in source_dict[\"biz_states\"]:\n",
        "              result_dict[\"biz_state\"].append(current_state)\n",
        "            \n",
        "            # inc_in\n",
        "            for current_inc_state in source_dict[\"inc_states\"]:\n",
        "              result_dict[\"inc_in\"].append(current_inc_state)\n",
        "\n",
        "          except:\n",
        "            print(\"Failed to read a non-critical result attribute, information may be missing.\")\n",
        "\n",
        "          # Append the result_dict to the list we will return\n",
        "          results_list.append(result_dict)\n",
        "\n",
        "        # Critical key (or _source dictionary) was missing \n",
        "        else:\n",
        "          print(\"Failed to read result _source dictionary or other critical JSON key, skipping.\")\n",
        "          continue\n",
        "      \n",
        "    except:\n",
        "      break\n",
        "\n",
        "    # Tally total number parsed so far. If we have hit the end, stop\n",
        "    hits_parsed += hit_index + 1\n",
        "    if hits_parsed >= hits_total:\n",
        "      break\n",
        "    \n",
        "    # Otherwise, update \"from\" query parameter for next batch\n",
        "    query_data[\"from\"] = hits_parsed\n",
        "\n",
        "    # Send another request\n",
        "    response = requests.post(url = \"https://efts.sec.gov/LATEST/search-index/\", headers = request_headers, json = query_data) \n",
        "    response.raise_for_status()\n",
        "\n",
        "    # Read into the response_dict dictionary and restart loop\n",
        "    response_dict = json.loads(response.content)\n",
        "\n",
        "  return results_list"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Support method to build filing document URL from dictionary returned by full text query\n",
        "def url_from_full_text_dict(full_text_result_dict):\n",
        "\n",
        "  # Remove hyphens from accession number\n",
        "  clean_accession = full_text_result_dict[\"accession\"].replace(\"-\",\"\")\n",
        "\n",
        "  # There may be multiple CIKs. The file should be available under each one using the same accession number and filename. Loop through and use the sane value. Not worth sending another request here.\n",
        "  for current_cik in full_text_result_dict[\"cik\"]:\n",
        "\n",
        "    # Sanity check\n",
        "    if len(current_cik) > 0:\n",
        "      # Build URL return\n",
        "      return \"https://www.sec.gov/Archives/edgar/data/\" + current_cik + \"/\" + clean_accession + \"/\" + full_text_result_dict[\"filename\"]\n",
        "\n",
        "  return \"\""
      ],
      "metadata": {
        "id": "qjRPDFFxktMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "results = list_results_full_text_query(query_string = \"ABCELLERA\")\n",
        "\n",
        "for hit in results:\n",
        "  print(url_from_full_text_dict(hit))\n",
        "\n",
        "print(\"Num of results: {}\".format(len(results)))"
      ],
      "metadata": {
        "id": "PppNMsSenX4S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}