{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN7R+0INNz2OQzKRCA9flrI"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# HTTP lib\n",
        "import requests\n",
        "\n",
        "# Used to decide what quarter we are in\n",
        "from datetime import date"
      ],
      "metadata": {
        "id": "EH6IwcWEHGOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The following guidance is given by the SEC website on the daily and full index files (from https://www.sec.gov/os/accessing-edgar-data):\n",
        "```\n",
        "Using the EDGAR index files\n",
        "\n",
        "Indexes to all public filings are available from 1994Q3 through the present and located in the following browsable directories:\n",
        "\n",
        "    /Archives/edgar/daily-index — daily index files through the current year;\n",
        "    /Archives/edgar/full-index — full indexes offer a \"bridge\" between quarterly and daily indexes, compiling filings from the beginning of the current quarter through the previous business day. At the end of the quarter, the full index is rolled into a static quarterly index.\n",
        "\n",
        "Each directory and all child subdirectories contain three files to assist in automated crawling of these directories. Note that these are not visible through directory browsing.\n",
        "\n",
        "    index.html (the web browser would normally receive these)\n",
        "    index.xml (an XML structured version of the same content)\n",
        "    index.json (a JSON structured vision of the same content)\n",
        "\n",
        "The EDGAR indexes list the following information for each filing:\n",
        "\n",
        "    company name\n",
        "    form type\n",
        "    central index key (CIK)\n",
        "    date filed\n",
        "    file name (including folder path)\n",
        "\n",
        "Four types of indexes are available:\n",
        "\n",
        "    company — sorted by company name\n",
        "    form — sorted by form type\n",
        "    master — sorted by CIK number\n",
        "    XBRL — list of submissions containing XBRL financial files, sorted by CIK number; these include Voluntary Filer Program submissions\n",
        "\n",
        "The company, form, and master indexes contain the same information sorted differently\n",
        "```\n",
        "Additionally:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Paths and directory structure\n",
        "\n",
        "The index paths link to the raw text version of the complete disseminated filing content, for example:\n",
        "\n",
        "    /Archives/edgar/data/1122304/0001193125-15-118890.txt\n",
        "\n",
        "Post-EDGAR 7.0 filings (after May 26, 2000) are also accessible via an alternative symbolic path, incorporating an intermediate accession-number directory without dashes. All the documents submitted for a given filing will be in this directory:\n",
        "\n",
        "    /Archives/edgar/data/1122304/000119312515118890/0001193125-15-118890.txt\n",
        "\n",
        "Other content that may be of interest using the root path:\n",
        "\n",
        "    /Archives/edgar/data/1122304/0001193125-15-118890-index.html — an HTML version including hyperlinked table of submitted documents.\n",
        "    /Archives/edgar/data/1122304/000119312515118890/0001193125-15-118890.hdr.sgml —\n",
        "    the SGML header contents. Note the additional \"accession-number-without-dashes\" directory in the path.\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "We primarily want to be able to search these indexes by CIK, form type, or date range. We will focus on the \"master\" index format as it is the most easily parsed. The XBRL indexes (only offered under full-index) may also be of interest. Simply replace \"master.idx\" with \"xbrl.idx\" in the below methods. IDX file structure and delimiters are the same as master.idx shown below:\n"
      ],
      "metadata": {
        "id": "cx9RzHKqcQhQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Full-index master.idx format:\n",
        "\n",
        "\n",
        "```\n",
        "Description:           Master Index of EDGAR Dissemination Feed\n",
        "Last Data Received:    June 30, 2022\n",
        "Comments:              webmaster@sec.gov\n",
        "Anonymous FTP:         ftp://ftp.sec.gov/edgar/\n",
        "Cloud HTTP:            https://www.sec.gov/Archives/\n",
        "\n",
        " \n",
        " \n",
        " \n",
        "CIK|Company Name|Form Type|Date Filed|Filename\n",
        "--------------------------------------------------------------------------------\n",
        "1000045|NICHOLAS FINANCIAL INC|10-K|2022-06-24|edgar/data/1000045/0000950170-22-012061.txt\n",
        "1000045|NICHOLAS FINANCIAL INC|3|2022-05-19|edgar/data/1000045/0001929257-22-000001.txt\n",
        "1000045|NICHOLAS FINANCIAL INC|4|2022-05-11|edgar/data/1000045/0001000045-22-000003.txt\n",
        "...\n",
        "```\n",
        "Our lines of interest begin after a line of many consecutive \"-\" characters followed by a newline. Each value/column of the lines are separated by pipe characters (\"|\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Sfx3AXnjRdsZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Daily-index master.idx format:\n",
        "\n",
        "\n",
        "```\n",
        "Description:           Daily Index of EDGAR Dissemination Feed\n",
        "Last Data Received:    Sep 26, 2022\n",
        "Comments:              webmaster@sec.gov\n",
        "Anonymous FTP:         ftp://ftp.sec.gov/edgar/\n",
        " \n",
        "CIK|Company Name|Form Type|Date Filed|File Name\n",
        "--------------------------------------------------------------------------------\n",
        "1000228|HENRY SCHEIN INC|4|20220926|edgar/data/1000228/0001209191-22-051256.txt\n",
        "1000275|ROYAL BANK OF CANADA|424B2|20220926|edgar/data/1000275/0001140361-22-034664.txt\n",
        "```\n",
        "Only difference is no dashes are in the date. It is in the format YYYYMMDD.\n"
      ],
      "metadata": {
        "id": "bG3tGL9X8Kpr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Support method used below. Given a date object, determines the quarter number. \n",
        "# Quarters are literally just divided into four 3-month groups: Jan-Mar, Apr-Jun, Jul-Sep, Oct-Dec (month 1-3, 4-6, 7-9, 10-12)\n",
        "def get_quarter_from_date(date_obj):\n",
        "  if (date_obj.month >= 1 and date_obj.month <= 3):\n",
        "    return 1\n",
        "  elif (date_obj.month >= 4 and date_obj.month <= 6):\n",
        "    return 2\n",
        "  elif (date_obj.month >= 7 and date_obj.month <= 9):\n",
        "    return 3\n",
        "  elif (date_obj.month >= 10 and date_obj.month <= 12):\n",
        "    return 4\n",
        "  else:\n",
        "    print(\"Failed to determine quarter from given date.\")\n",
        "  \n",
        "  return 0"
      ],
      "metadata": {
        "id": "JIGqQpoNlphz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Filtering filings by CIK, company name, form type, or date\n",
        "\n",
        "This first method filters the given (year and) quarter's master index to return a list of filings according to a given filter type and list of target values. The next method achieves the same thing but using the daily-index instead."
      ],
      "metadata": {
        "id": "vFHaF1DBEnSv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZF_YtkvEaM1g"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "filter_type = \"cik\", \"company\", \"type\", or \"date\"\n",
        "unique_vals = [] # List of unique values (CIKs, company names, types, or dates). NOTE: Dates should be passed as a list of date objects\n",
        "\n",
        "Returns a list of dictionaries of the following structure:\n",
        "{\n",
        "  \"cik\" : \"CIK_NUM\",\n",
        "  \"company\" : \"COMPANY_NAME\",\n",
        "  \"type\" : \"FILING_TYPE\",\n",
        "  \"date\" : \"YYYY-MM-DD\",\n",
        "  \"fulltext_path\" : \".../edgar/data/CIK/ETC\"\n",
        "}\n",
        "\"\"\"\n",
        "def filter_quarter_by_param(target_year, target_quarter, filter_type, unique_vals = ()):\n",
        "\n",
        "  filings_list = []\n",
        "\n",
        "  # Figure out what kind of filter and format the unique values if needed\n",
        "  clean_unique_vals = []\n",
        "  filter_column = 0\n",
        "\n",
        "  if filter_type == \"cik\":\n",
        "    # Strip leading 0's for consistency. The IDX files won't include them from what I've seen.\n",
        "    for i in unique_vals:\n",
        "      clean_unique_vals.append(str(i).lstrip(\"0\"))\n",
        "\n",
        "  elif filter_type == \"company\":\n",
        "    filter_column = 1\n",
        "    for i in unique_vals:\n",
        "      clean_unique_vals.append(i.lower())\n",
        "\n",
        "  elif filter_type == \"type\":\n",
        "    filter_column = 2\n",
        "    for i in unique_vals:\n",
        "      clean_unique_vals.append(i.lower())\n",
        "\n",
        "  elif filter_type == \"date\":\n",
        "    filter_column = 3\n",
        "    # Convert date structures into \"YYYY-MM-DD\" strings\n",
        "    try:\n",
        "      for d in unique_vals:\n",
        "        clean_unique_vals.append(\"{}-{}-{}\".format(d.year, str(d.month).zfill(2), str(d.day).zfill(2)))\n",
        "    except:\n",
        "      print(\"Invalid filter date objects passed.\")\n",
        "      return filings_list\n",
        "  \n",
        "  else:\n",
        "    print(\"Invalid quarterly filter type. Must be name, CIK, type, or date: {}\".format(filter_type))\n",
        "    return filings_list\n",
        "\n",
        "  # URLs and UA for full-index\n",
        "  qtr_index_url = r\"https://www.sec.gov/Archives/edgar/full-index/{}/QTR{}/master.idx\".format(target_year, target_quarter)\n",
        "  base_archives = \"https://www.sec.gov/Archives/\"\n",
        "  req_headers = { \"User-Agent\" : \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\" }\n",
        "\n",
        "  # Get the .idx file\n",
        "  resp = requests.get(url = qtr_index_url, headers = req_headers)\n",
        "  resp.raise_for_status()\n",
        "\n",
        "  # First separate the header from the lines of content. Look for twenty dashes in a row followed by a newline\n",
        "  idx_full_text = resp.text\n",
        "  split_idx = idx_full_text.split(\"--------------------\\n\")\n",
        "\n",
        "  # Loop through lines of data\n",
        "  try:\n",
        "    for line in split_idx[1].splitlines():\n",
        "\n",
        "      # CIK|Company Name|Form Type|Date Filed|Filename\n",
        "      # We expect 5 columns\n",
        "      columns = line.split(\"|\")\n",
        "      if len(columns) == 5:\n",
        "\n",
        "        if columns[filter_column].lower() in clean_unique_vals:\n",
        "          # Build a dictionary for the filing if we find match\n",
        "          found_filing = {}\n",
        "          found_filing[\"cik\"] = columns[0].zfill(10)\n",
        "          found_filing[\"company\"] = columns[1]\n",
        "          found_filing[\"type\"] = columns[2]\n",
        "          found_filing[\"date\"] = columns[3]\n",
        "          found_filing[\"fulltext_path\"] = base_archives + columns[4]\n",
        "\n",
        "          # Append it\n",
        "          filings_list.append(found_filing)\n",
        "  \n",
        "  except:\n",
        "    print(\"IDX file was in unexpected format, error parsing\")\n",
        "\n",
        "  return filings_list"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "todays_date = date.today()\n",
        "qtrnum = get_quarter_from_date(todays_date)\n",
        "\n",
        "if (qtrnum):\n",
        "  print(filter_quarter_by_param(todays_date.year, qtrnum, \"cik\", [320193]))"
      ],
      "metadata": {
        "id": "5Iny-TTAWY5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Similar to filter_quarter_by_param, but targets the daily-index of the given date object target_date. \n",
        "filter_type, unique_vals, and return list structure are all the same as filter_quarter_by_param\n",
        "\"\"\"\n",
        "def filter_day_by_param(target_date, filter_type, unique_vals = ()):\n",
        "\n",
        "  filings_list = []\n",
        "\n",
        "  # Verify that target_date is of the right type\n",
        "  if type(target_date) != date:\n",
        "    print(\"Invalid target date format (not a date object).\")\n",
        "    return filings_list\n",
        "\n",
        "  # Figure out what kind of filter and format the unique values if needed\n",
        "  clean_unique_vals = []\n",
        "  filter_column = 0\n",
        "\n",
        "  if filter_type == \"cik\":\n",
        "    # Strip leading 0's for consistency. The IDX files won't include them from what I've seen.\n",
        "    for i in unique_vals:\n",
        "      clean_unique_vals.append(str(i).lstrip(\"0\"))\n",
        "\n",
        "  elif filter_type == \"company\":\n",
        "    filter_column = 1\n",
        "    for i in unique_vals:\n",
        "      clean_unique_vals.append(i.lower())\n",
        "\n",
        "  elif filter_type == \"type\":\n",
        "    filter_column = 2\n",
        "    for i in unique_vals:\n",
        "      clean_unique_vals.append(i.lower())\n",
        "\n",
        "  elif filter_type == \"date\":\n",
        "    filter_column = 3\n",
        "    # Convert date structures into \"YYYY-MM-DD\" strings\n",
        "    try:\n",
        "      for d in unique_vals:\n",
        "        clean_unique_vals.append(\"{}-{}-{}\".format(d.year, str(d.month).zfill(2), str(d.day).zfill(2)))\n",
        "    except:\n",
        "      print(\"Invalid filter date objects passed.\")\n",
        "      return filings_list\n",
        "\n",
        "  else:\n",
        "    print(\"Invalid daily filter type. Must be name, CIK, type, or date: {}\".format(filter_type))\n",
        "    return filings_list\n",
        "\n",
        "  # Build path\n",
        "  daily_index_url = r\"https://www.sec.gov/Archives/edgar/daily-index/{}/QTR{}/master.{}{}{}.idx\".format(target_date.year, get_quarter_from_date(target_date), target_date.year, \\\n",
        "                                                                                                       str(target_date.month).zfill(2), str(target_date.day).zfill(2)) # master.YYYYMMDD.idx\n",
        "  base_archives = \"https://www.sec.gov/Archives/\"\n",
        "  req_headers = { \"User-Agent\" : \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\" }\n",
        "\n",
        "  # Get the file\n",
        "  resp = requests.get(url = daily_index_url, headers = req_headers)\n",
        "  resp.raise_for_status()\n",
        "\n",
        "  # Separate the header\n",
        "  idx_full_text = resp.text\n",
        "  split_idx = idx_full_text.split(\"--------------------\\n\")\n",
        "\n",
        "  # Loop through lines of data\n",
        "  try:\n",
        "    for line in split_idx[1].splitlines():\n",
        "\n",
        "      # CIK|Company Name|Form Type|Date Filed|Filename\n",
        "      # We expect 5 columns\n",
        "      columns = line.split(\"|\")\n",
        "      if len(columns) == 5:\n",
        "\n",
        "        if columns[filter_column].lower() in clean_unique_vals:\n",
        "          # Build a dictionary for the filing if we find match\n",
        "          found_filing = {}\n",
        "          found_filing[\"cik\"] = columns[0].zfill(10)\n",
        "          found_filing[\"company\"] = columns[1]\n",
        "          found_filing[\"type\"] = columns[2]\n",
        "          found_filing[\"date\"] = columns[3]\n",
        "          found_filing[\"fulltext_path\"] = base_archives + columns[4]\n",
        "\n",
        "          # Append it\n",
        "          filings_list.append(found_filing)\n",
        "  \n",
        "  except:\n",
        "    print(\"IDX file was in unexpected format, error parsing\")\n",
        "\n",
        "  return filings_list"
      ],
      "metadata": {
        "id": "x4gbily_8sz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_date = date(2022, 9, 26)\n",
        "print(filter_day_by_param(test_date, \"type\", [\"4\"]))"
      ],
      "metadata": {
        "id": "Mty8grPlAS8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sorting/grouping filings by CIK, company name, form type, or date\n",
        "These methods return a dictionary. At the first level, the key `sort_type` tells what column the results have been grouped by. \n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "{\n",
        "  \"sort_type\" : \"\", # Either \"cik\", \"name\", \"type\", or \"date\"\n",
        "  \"results\" : []\n",
        "}\n",
        "```\n",
        "The `results` key contains a list of dictionaries, one formed for each unique value of the \"sorting\" parameter (CIK, company name, form type, or date) which is found in the IDX file. \n",
        "```\n",
        "{\n",
        "  \"UNIQUE_VAL\" : [] # List of filings under that unique value. Dictionaries of the following format:\n",
        "}\n",
        "```\n",
        "The structure of these dictionaries is as follows:\n",
        "```\n",
        "{\n",
        "  \"cik\" : \"CIK_NUM\",\n",
        "  \"company\" : \"COMPANY_NAME\",\n",
        "  \"type\" : \"FILING_TYPE\",\n",
        "  \"date\" : \"YYYY-MM-DD\", # For full-index IDX\n",
        "  \"fulltext_path\" : \".../edgar/data/CIK/ETC\"\n",
        "}\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "8HyzGUEbqUj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sort_quarter_by_param(target_year, target_quarter, sort_type):\n",
        "\n",
        "  master_dict = {}\n",
        "\n",
        "  # Figure out what type of sort we are doing. This will be our \"column\" of interest below. \n",
        "  sorting_column = 0\n",
        "  if sort_type == \"cik\":\n",
        "    pass\n",
        "  elif sort_type == \"name\":\n",
        "    sorting_column = 1\n",
        "  elif sort_type == \"type\":\n",
        "    sorting_column = 2\n",
        "  elif sort_type == \"date\":\n",
        "    sorting_column = 3\n",
        "  else:\n",
        "    print(\"Invalid sort type: {}\".format(sort_type))\n",
        "    return master_dict\n",
        "\n",
        "  master_dict[\"sort_type\"] = sort_type\n",
        "  master_dict[\"results\"] = []\n",
        "\n",
        "  # Download the IDX content\n",
        "  qtr_index_url = r\"https://www.sec.gov/Archives/edgar/full-index/{}/QTR{}/master.idx\".format(target_year, target_quarter)\n",
        "  base_archives = \"https://www.sec.gov/Archives/\"\n",
        "  req_headers = { \"User-Agent\" : \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\" }\n",
        "\n",
        "  resp = requests.get(url = qtr_index_url, headers = req_headers)\n",
        "  resp.raise_for_status()\n",
        "\n",
        "  # Separate the header \n",
        "  idx_full_text = resp.text\n",
        "  split_idx = idx_full_text.split(\"--------------------\\n\")\n",
        "\n",
        "  # Loop through lines of data\n",
        "  try:\n",
        "    for line in split_idx[1].splitlines():\n",
        "\n",
        "      # CIK|Company Name|Form Type|Date Filed|Filename\n",
        "      # We expect 5 columns\n",
        "      columns = line.split(\"|\")\n",
        "      if len(columns) == 5:\n",
        "\n",
        "        filing_dict = {}\n",
        "        filing_dict[\"cik\"] = columns[0].zfill(10)\n",
        "        filing_dict[\"company\"] = columns[1]\n",
        "        filing_dict[\"type\"] = columns[2]\n",
        "        filing_dict[\"date\"] = columns[3]\n",
        "        filing_dict[\"fulltext_path\"] = base_archives + columns[4]\n",
        "        \n",
        "        # Append to the list in the existing dictionary if this sorting value has been found before\n",
        "        for c_item in master_dict[\"results\"]:\n",
        "          if columns[sorting_column] in c_item.keys():\n",
        "            c_item[columns[sorting_column]].append(filing_dict)\n",
        "            break\n",
        "        \n",
        "        # Gets executed if break never gets hit\n",
        "        else:\n",
        "          # Has not been encountered. Initialize a dictionary for the unique value then append the filing info to it.\n",
        "          unique_val_dict = { columns[sorting_column] : [] }\n",
        "          unique_val_dict[columns[sorting_column]].append(filing_dict)\n",
        "          master_dict[\"results\"].append(unique_val_dict)\n",
        "\n",
        "  except:\n",
        "    print(\"IDX file was in unexpected format, error parsing\")\n",
        "\n",
        "  return master_dict"
      ],
      "metadata": {
        "id": "EtCofoKptNTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sort_quarter_by_param(\"2022\", \"3\", \"cik\")"
      ],
      "metadata": {
        "id": "QqEBD5kK_KgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Similar method but uses the daily-index. Takes a date object as a parameter. NOTE: filing_dict objects of this method return date in YYYYMMDD format rather than YYYY-MM-DD\n",
        "def sort_day_by_param(target_date, sort_type):\n",
        "\n",
        "  master_dict = {}\n",
        "\n",
        "  # Figure out what type of sort we are doing. This will be our \"column\" of interest below. \n",
        "  sorting_column = 0\n",
        "  if sort_type == \"cik\":\n",
        "    pass\n",
        "  elif sort_type == \"name\":\n",
        "    sorting_column = 1\n",
        "  elif sort_type == \"type\":\n",
        "    sorting_column = 2\n",
        "  elif sort_type == \"date\":\n",
        "    sorting_column = 3\n",
        "  else:\n",
        "    print(\"Invalid sort type: {}\".format(sort_type))\n",
        "    return master_dict\n",
        "\n",
        "  master_dict[\"sort_type\"] = sort_type\n",
        "  master_dict[\"results\"] = []\n",
        "\n",
        "  # Build path\n",
        "  daily_index_url = r\"https://www.sec.gov/Archives/edgar/daily-index/{}/QTR{}/master.{}{}{}.idx\".format(target_date.year, get_quarter_from_date(target_date), target_date.year, \\\n",
        "                                                                                                       str(target_date.month).zfill(2), str(target_date.day).zfill(2)) # master.YYYYMMDD.idx\n",
        "  base_archives = \"https://www.sec.gov/Archives/\"\n",
        "  req_headers = { \"User-Agent\" : \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\" }\n",
        "\n",
        "  # Get contents\n",
        "  resp = requests.get(url = daily_index_url, headers = req_headers)\n",
        "  resp.raise_for_status()\n",
        "\n",
        "  # Separate the header \n",
        "  idx_full_text = resp.text\n",
        "  split_idx = idx_full_text.split(\"--------------------\\n\")\n",
        "\n",
        "  # Loop through lines of data\n",
        "  try:\n",
        "    for line in split_idx[1].splitlines():\n",
        "\n",
        "      # CIK|Company Name|Form Type|Date Filed|Filename\n",
        "      # We expect 5 columns\n",
        "      columns = line.split(\"|\")\n",
        "      if len(columns) == 5:\n",
        "\n",
        "        filing_dict = {}\n",
        "        filing_dict[\"cik\"] = columns[0].zfill(10)\n",
        "        filing_dict[\"company\"] = columns[1]\n",
        "        filing_dict[\"type\"] = columns[2]\n",
        "        filing_dict[\"date\"] = columns[3]\n",
        "        filing_dict[\"fulltext_path\"] = base_archives + columns[4]\n",
        "        \n",
        "        # Append to the list in the existing dictionary if this sorting value has been found before\n",
        "        for c_item in master_dict[\"results\"]:\n",
        "          if columns[sorting_column] in c_item.keys():\n",
        "            c_item[columns[sorting_column]].append(filing_dict)\n",
        "            break\n",
        "        \n",
        "        # Gets executed if break never gets hit\n",
        "        else:\n",
        "          # Has not been encountered. Initialize a dictionary for the unique value then append the filing info to it.\n",
        "          unique_val_dict = { columns[sorting_column] : [] }\n",
        "          unique_val_dict[columns[sorting_column]].append(filing_dict)\n",
        "          master_dict[\"results\"].append(unique_val_dict)\n",
        "\n",
        "  except:\n",
        "    print(\"IDX file was in unexpected format, error parsing\")\n",
        "\n",
        "  return master_dict"
      ],
      "metadata": {
        "id": "VjVJaoG-g9IP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_date = date(2022, 9, 26)\n",
        "print(sort_day_by_param(test_date, \"name\"))"
      ],
      "metadata": {
        "id": "omjeBOyjmbFm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}